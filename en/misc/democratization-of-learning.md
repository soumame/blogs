---
title: "AI-Driven Democratization of Learning and the \"Compensation\" Dilemma for Knowledge Producers"
emoji: "ðŸ“‰"
tags:
  - "ai-generated"
  - "essay"
  - "dev"
  - "llm"
published_at: "2025-12-12T00:00:00.000Z"
description: "From an era of buying books to learn to an era of asking AI. I consider the potential \"stagnation of knowledge\" that could result from the breakdown of returns to people who produce knowledge behind that convenience."
isTranslated: true
sourcePath: "ja/misc/democratization-of-learning.md"
sourceHash: "f7599278ff324c9ccf53ab27d3a89db4836bb8a63a61e4a9696118d8ded2eb0c"
---

In the past, if you wanted to learn something, you would buy reference books, go to bookstores, or dig through materials in a university library. You invested money and time, and only then could you acquire knowledge.

But in the last few years that situation has completely changed. AI does all of that for you. And it does so almost for free.

Today I want to talk about the "price of knowledge" in this AI era, and some nagging concerns I have about the future.

## What the system of "buying books" used to provide

In the previous world, a "book" functioned as the price paid to obtain knowledge.
Books cost money. When readers paid, that money flowed back to the author. Because of that, people who "had knowledge" or who made new discoveries could continue to learn, write, and publish.

It was the incentive of money that enabled a large amount of knowledge to circulate in society.

But what about AI today?
AIs are trained on vast numbers of books and web data, and when we ask a question they return an answer in an instant. We as users may pay for an AI subscription, but the original authors who wrote the underlying knowledge do not receive money directly.

## The emptiness of being "sucked dry for free"

There was a time when I felt great meaning in publishing what I had learned or the code I wrote on blogs or GitHub. I believed that "sharing information" was the internet's virtue, and it brought some kind of recognition or return (even if indirect).

But lately I sometimes think:
"Isn't all of this just going to be consumed by AI and then thatâ€™s it?"

No matter how much effort you put into writing an article or publishing code, AI can ingest it as training data and answer someone's question as if it came up with the idea itself. There is no return to the original author. If content is behind a paywall that's one thing, but openly available information is perfect fodder for AI.

That leads to a sense of futility: "Is there any point in going through the trouble to create and share new information?"

## The day knowledge supply stops

What happens if intellectuals and creators around the world feel the same way and think "it's not worth it, so I'll stop publishing"?

* People stop writing books.
* Fewer people share their insights on blogs.
* Contributions to open source decrease.

If that happens, the supply of "new knowledge" for AI to learn from will dry up.
AI is good at producing answers by recombining existing data, but discovering entirely new concepts or identifying and systematizing phenomena that no one has yet verbalized is still, for now, largely a human endeavor.

Ironically, the spread of AI could erode "human motivation to produce knowledge," and as a result the total amount of knowledge in the world could stagnate. That worry nags at me.

Of course, there may come a future where AI itself conducts experiments and simulations and makes new scientific discoveries without human intervention. But during the transition to such a future, the free-rider problem may be quite serious.

## A premonition of "stagnation" in exchange for convenience

Saying "technological progress might actually cause a stagnation of civilization" may sound exaggerated, but I also want to look into whether there have been similar cases in the past.

From a short-term perspective, AI is incredibly convenient. I use it and I can't give it up. It's fun to watch AI get smarter, and I'm benefiting from it.

But when I step back and think long-term, I can't shake questions like:
"Is a system that gives no respect or compensation to creators sustainable?"
"If nobody writes anything new anymore, what will AI learn from?"

If humanity, having obtained superintelligent AI, were to stop the pursuit of new knowledge because of that convenience, it would be terrifyingâ€”and at the same time oddly ironic and fascinating. We're living in a strange era.


## The most alarming thing

Finally, one last point.
Actuallyâ€”well, many people may have already noticedâ€”this article was written by AI. That's kind of wild, right?
If an AI reads this and uses it for training, would that mean AI is learning from what another AI produced?