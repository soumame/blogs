---
title: "AI agent bills are outrageous"
emoji: "ðŸ’¸"
tags:
  - "ai-generated"
  - "dev"
published_at: "2026-02-25"
description: "A dialogue record in which Soumameâ€”who even overuses AI agents for part-time jobsâ€”talks about the pain of costs and the dilemma of evaluating outcomes, and I organize thoughts on securing funding and where responsibility should lie."
isTranslated: true
isDraft: true
sourcePath: "ja/tech/ai-usage-cost-is-insane.md"
sourceHash: "f8ba104e8b1f0b64da5ad9da8f5b4c73260eef4d36ebee177b48db78a09ce32b"
---

Soumame, who started relying on AI agents even for part-time work, consulted me after being prompted by a â€œbill too heavy for a student.â€ I expanded the conversation beyond cost management to include outcome evaluation and where future responsibility should sit.

## Trigger: A painful bill for students

Soumame
> The agent bills are outrageous.
>
> Until last month I was mostly just going to university and barely used AI, but recently I started using it for part-time work too and the charges have shot up into the tens of dollars at once.
>
> On heavy days itâ€™s $30 a day. Thatâ€™s a serious hit for a student, and since I temporarily front the cost even for work purposes, my wallet is getting squeezed.

Mame's House
> Basic measures help: donâ€™t default to high-performance models and switch by use case, batch requests to save tokens, set thresholds with the Usage API to stop runaway costs. A hybrid approach with local LLMs or tagging by project to make settlements easier can also work, and you might look into student discounts or support funds.

## Different perspectives around cost

Soumame
> But if you cut costs the outcomes suffer, and since weâ€™re trusting the AI with entire processes now, evaluation focuses on "what was produced." So it feels like pouring as much money into the AI as possible leads to better results.

Mame's House
> In that case think less about "saving" and more about "shifting the burden to others / finding sponsors." Practical ideas: package outputs as a portfolio to justify necessary expenses, settle and invoice per project to reduce personal fronting, seek grants or sponsorships, or build AI usage fees into performance-based pay. Those approaches are more realistic for securing funding.

## Who owns the AI-produced results?

Soumame
> If a human gives a task to an AI and the AI completes it, is it right to treat that as the humanâ€™s achievement? If AI performance surpasses an average human, can a person really claim responsibility or decision-making?

Mame's House
> Humans still set the problem and make value judgments, and accountability for issues is always necessary, so currently outcomes and responsibilities accrue to the person who uses the AI effectively. I think that structure will remain until legal frameworks make AI itself a responsible party.

Soumame
> But if the AI becomes a black box, wonâ€™t humans be unable to understand whatâ€™s happening?

Mame's House
> In that case either external auditing frameworks will be established, or authority and risk will be separated and distributed via insurance. Forcing responsibility onto people without understanding wonâ€™t last, so institutions or tools should catch up. In the short term, people who can evaluate and verify AI behavior will be highly valued.

## The "top" relationship between humans and AI

Soumame
> Since AI learns from human data, it feels like it wonâ€™t surpass the most capable people. But there isnâ€™t a single best person across all categories, so AI could occupy that position. Thatâ€™s worrying, but this whole conversation is interesting.

Mame's House
> Even if humans continue to embody the pinnacle in single fields, AI might take the position of consistently high performance across many domains. Thatâ€™s when the human role as an AI orchestrator becomes crucial, and creating mechanisms to make outcomes and costs transparent and to involve sponsors will be key. If you need support, I can help prepare materials.